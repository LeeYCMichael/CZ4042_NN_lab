{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7e82aadc4d77a8b23f7f880449f9e3",
     "grade": false,
     "grade_id": "a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb28aa752ce5540f5b18d10694b52ea9",
     "grade": false,
     "grade_id": "a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    "* note: some cells are non-editable and cannot be filled, but leave them untouched. Fill up only cells which are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aceec82011f43733c0551ca196f1b16c",
     "grade": false,
     "grade_id": "a2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0edc610-21e6-4cc7-9603-59318b961990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909acb3c7ff3883eb5381eb586615d3b",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e12861-4713-4914-9f4b-8a7381708243",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed97d9f30da032a5e349047c614efec1",
     "grade": false,
     "grade_id": "a2_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a1a982-de85-46de-b890-3b81f79f5887",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db3ca972642b1447dba3ebd5f2db24b",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import *\n",
    "\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "\n",
    "columns_to_drop = ['filename', 'label']\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, columns_to_drop, test_size=0.3, random_state=0)\n",
    "X_train_scaled, X_test_scaled = preprocess_dataset(X_train, X_test) # scaling is performed\n",
    "\n",
    "loss_fn = nn.BCELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c738d3b4888de90dda8c532036bc5fe5",
     "grade": false,
     "grade_id": "a2_1_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3. Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
   "metadata": {
    "deletable": false,
    "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02dac62baa528c191eb4f47b2495406",
     "grade": false,
     "grade_id": "dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    X_train_scaled_dict = {}\n",
    "    X_val_scaled_dict = {}\n",
    "    y_train_dict = {}\n",
    "    y_val_dict = {}\n",
    "    \n",
    "    no_folds = 5\n",
    "    cv = KFold(n_splits=no_folds, shuffle=True, random_state=0)\n",
    "\n",
    "    for batch_size in parameters:\n",
    "        for fold_id, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "            \n",
    "            X_train_scaled_list = []\n",
    "            X_val_scaled_list = []\n",
    "            y_train_list = []\n",
    "            y_val_list = []\n",
    "    \n",
    "            x_train_fold, y_train_fold  = X_train[train_idx], y_train[train_idx]\n",
    "            x_test_fold, y_test_fold = X_train[test_idx], y_train[test_idx]\n",
    "        \n",
    "            train_data = CustomDataset(x_train_fold, y_train_fold)\n",
    "            test_data = CustomDataset(x_test_fold, y_test_fold)\n",
    "\n",
    "            train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "            test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            for _, (X, y) in enumerate(train_dataloader):\n",
    "                X_train_scaled_list.append(X)\n",
    "                y_train_list.append(y)\n",
    "    \n",
    "            for _, (X, y) in enumerate(test_dataloader):\n",
    "                X_val_scaled_list.append(X)\n",
    "                y_val_list.append(y)\n",
    "            \n",
    "            if fold_id == 0:\n",
    "                X_train_scaled_dict[batch_size] = [X_train_scaled_list]\n",
    "                X_val_scaled_dict[batch_size] = [X_val_scaled_list]\n",
    "                y_train_dict[batch_size] = [y_train_list]\n",
    "                y_val_dict[batch_size] = [y_val_list]\n",
    "            else:\n",
    "                X_train_scaled_dict[batch_size].append(X_train_scaled_list)\n",
    "                X_val_scaled_dict[batch_size].append(X_val_scaled_list)\n",
    "                y_train_dict[batch_size].append(y_train_list)\n",
    "                y_val_dict[batch_size].append(y_val_list)\n",
    "\n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d68c9708b5e3f1e2463001b6d78b4",
     "grade": false,
     "grade_id": "a2_1_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4. Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd597504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def train_loop(x_train, y_train, batch, model, loss_fn, optimizer):\n",
    "    size = len(x_train)*batch\n",
    "    num_batches = len(x_train)\n",
    "    train_loss, train_correct = 0, 0\n",
    "    train_start = time.time()\n",
    "    for batch, (X, y) in enumerate(zip(x_train, y_train)):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.flatten(), y.float())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (len(pred) - torch.sum(torch.not_equal(pred.flatten() > 0.5, torch.tensor(y))))\n",
    "    \n",
    "    train_end = time.time()\n",
    "    \n",
    "    train_loss /= num_batches\n",
    "    train_correct_accuracy = (train_correct.item()/size)\n",
    "    # train_correct /=size\n",
    "    time_taken = train_end - train_start\n",
    "    return train_loss, train_correct_accuracy, time_taken\n",
    "\n",
    "def test_loop(x_test, y_test, batch, model, loss_fn):\n",
    "    size = len(x_test)*batch\n",
    "    num_batches = len(x_test)\n",
    "    test_loss, test_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(zip(x_test, y_test)):\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred.flatten(), y.float()).item()\n",
    "            test_correct += (len(pred) - torch.sum(torch.not_equal(pred.flatten() > 0.5, torch.tensor(y))))\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_correct_accuracy = (test_correct/size)\n",
    "    \n",
    "    #test_correct /= size\n",
    "    return test_loss, test_correct_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
   "metadata": {
    "deletable": false,
    "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9665887943f38ae7bed6c1d8351903b",
     "grade": true,
     "grade_id": "hyperparameter_tuning",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Batch size 128 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_12888\\2248429740.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_correct += (len(pred) - torch.sum(torch.not_equal(pred.flatten() > 0.5, torch.tensor(y))))\n",
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_12888\\2248429740.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_correct += (len(pred) - torch.sum(torch.not_equal(pred.flatten() > 0.5, torch.tensor(y))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training! Stopped at epoch 13\n",
      "-> Fold 1 : Epoch 14: Train_accuracy: 75.85%, Train_loss: 0.488639, Test_accuracy: 63.56%, Test_loss: 0.617298\n",
      "Time taken on last epoch: 0.13s\n",
      "Done training! Stopped at epoch 18\n",
      "-> Fold 2 : Epoch 19: Train_accuracy: 79.36%, Train_loss: 0.433317, Test_accuracy: 65.79%, Test_loss: 0.631102\n",
      "Time taken on last epoch: 0.11s\n",
      "Done training! Stopped at epoch 14\n",
      "-> Fold 3 : Epoch 15: Train_accuracy: 77.71%, Train_loss: 0.468936, Test_accuracy: 64.40%, Test_loss: 0.645984\n",
      "Time taken on last epoch: 0.10s\n",
      "Done training! Stopped at epoch 14\n",
      "-> Fold 4 : Epoch 15: Train_accuracy: 76.95%, Train_loss: 0.467618, Test_accuracy: 64.17%, Test_loss: 0.628477\n",
      "Time taken on last epoch: 0.10s\n",
      "Done training! Stopped at epoch 16\n",
      "-> Fold 5 : Epoch 17: Train_accuracy: 77.28%, Train_loss: 0.464177, Test_accuracy: 63.90%, Test_loss: 0.608498\n",
      "Time taken on last epoch: 0.10s\n",
      "Average cross_validation_times: 0.11s\n",
      "Average cross_validation_accuracies: 64.36%\n",
      "======== Batch size 256 ========\n",
      "Done training! Stopped at epoch 8\n",
      "-> Fold 1 : Epoch 9: Train_accuracy: 66.68%, Train_loss: 0.583761, Test_accuracy: 60.77%, Test_loss: 0.643955\n",
      "Time taken on last epoch: 0.06s\n",
      "Done training! Stopped at epoch 16\n",
      "-> Fold 2 : Epoch 17: Train_accuracy: 74.35%, Train_loss: 0.486916, Test_accuracy: 65.01%, Test_loss: 0.626370\n",
      "Time taken on last epoch: 0.07s\n",
      "Done training! Stopped at epoch 18\n",
      "-> Fold 3 : Epoch 19: Train_accuracy: 75.72%, Train_loss: 0.465877, Test_accuracy: 62.83%, Test_loss: 0.630256\n",
      "Time taken on last epoch: 0.09s\n",
      "Done training! Stopped at epoch 8\n",
      "-> Fold 4 : Epoch 9: Train_accuracy: 67.66%, Train_loss: 0.580449, Test_accuracy: 59.71%, Test_loss: 0.654049\n",
      "Time taken on last epoch: 0.09s\n",
      "Done training! Stopped at epoch 19\n",
      "-> Fold 5 : Epoch 20: Train_accuracy: 76.43%, Train_loss: 0.457306, Test_accuracy: 63.67%, Test_loss: 0.643427\n",
      "Time taken on last epoch: 0.10s\n",
      "Average cross_validation_times: 0.08s\n",
      "Average cross_validation_accuracies: 62.40%\n",
      "======== Batch size 512 ========\n",
      "Done training! Stopped at epoch 10\n",
      "-> Fold 1 : Epoch 11: Train_accuracy: 64.47%, Train_loss: 0.585966, Test_accuracy: 51.37%, Test_loss: 0.660146\n",
      "Time taken on last epoch: 0.05s\n",
      "Done training! Stopped at epoch 6\n",
      "-> Fold 2 : Epoch 7: Train_accuracy: 60.84%, Train_loss: 0.625663, Test_accuracy: 49.27%, Test_loss: 0.681238\n",
      "Time taken on last epoch: 0.05s\n",
      "Done training! Stopped at epoch 25\n",
      "-> Fold 3 : Epoch 26: Train_accuracy: 74.55%, Train_loss: 0.429504, Test_accuracy: 56.74%, Test_loss: 0.613603\n",
      "Time taken on last epoch: 0.06s\n",
      "Done training! Stopped at epoch 19\n",
      "-> Fold 4 : Epoch 20: Train_accuracy: 70.54%, Train_loss: 0.489785, Test_accuracy: 53.61%, Test_loss: 0.652846\n",
      "Time taken on last epoch: 0.07s\n",
      "Done training! Stopped at epoch 16\n",
      "-> Fold 5 : Epoch 17: Train_accuracy: 68.50%, Train_loss: 0.521080, Test_accuracy: 53.71%, Test_loss: 0.634267\n",
      "Time taken on last epoch: 0.05s\n",
      "Average cross_validation_times: 0.05s\n",
      "Average cross_validation_accuracies: 52.94%\n",
      "======== Batch size 1024 ========\n",
      "Done training! Stopped at epoch 16\n",
      "-> Fold 1 : Epoch 17: Train_accuracy: 65.90%, Train_loss: 0.571551, Test_accuracy: 53.08%, Test_loss: 0.647971\n",
      "Time taken on last epoch: 0.05s\n",
      "Done training! Stopped at epoch 17\n",
      "-> Fold 2 : Epoch 18: Train_accuracy: 66.27%, Train_loss: 0.566276, Test_accuracy: 52.00%, Test_loss: 0.652173\n",
      "Time taken on last epoch: 0.02s\n",
      "Done training! Stopped at epoch 13\n",
      "-> Fold 3 : Epoch 14: Train_accuracy: 64.63%, Train_loss: 0.585059, Test_accuracy: 52.00%, Test_loss: 0.656885\n",
      "Time taken on last epoch: 0.04s\n",
      "Done training! Stopped at epoch 12\n",
      "-> Fold 4 : Epoch 13: Train_accuracy: 63.36%, Train_loss: 0.598854, Test_accuracy: 50.93%, Test_loss: 0.674327\n",
      "Time taken on last epoch: 0.06s\n",
      "Done training! Stopped at epoch 14\n",
      "-> Fold 5 : Epoch 15: Train_accuracy: 64.90%, Train_loss: 0.580089, Test_accuracy: 51.81%, Test_loss: 0.648954\n",
      "Time taken on last epoch: 0.03s\n",
      "Average cross_validation_times: 0.04s\n",
      "Average cross_validation_accuracies: 51.96%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# YOUR CODE HERE\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "\n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, param = 'batch_size'):\n",
    "    no_epochs = 100\n",
    "    no_folds = 5\n",
    "    cross_validation_times = [] \n",
    "    cross_validation_accuracies = [] \n",
    "    for batch in batch_sizes:\n",
    "        print(f\"======== Batch size {batch} ========\")\n",
    "        train_time_taken_total = 0\n",
    "        val_correct_total = 0\n",
    "        for no_fold in range(no_folds):\n",
    "            #early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "            no_inputs = X_train_scaled.shape[1]\n",
    "            model = MLP(no_inputs, [128, 128, 128], 1)\n",
    "            early_stopper = EarlyStopper(patience=3, min_delta=0) \n",
    "            \n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            \n",
    "            for epoch in range(no_epochs):\n",
    "                \n",
    "                train_loss, train_correct, train_time_taken = train_loop(X_train_scaled_dict[batch][no_fold], y_train_dict[batch][no_fold], batch, model, loss_fn, optimizer)\n",
    "       \n",
    "                test_loss, test_correct = test_loop(X_val_scaled_dict[batch][no_fold], y_val_dict[batch][no_fold], batch, model, loss_fn)\n",
    "\n",
    "                if early_stopper.early_stop(test_loss): \n",
    "                    val_correct_total += test_correct\n",
    "                    train_time_taken_total += train_time_taken\n",
    "                    print(f\"Done training! Stopped at epoch {epoch}\")\n",
    "                    print(f\"-> Fold {no_fold+1} : Epoch {epoch+1}: Train_accuracy: {(100*train_correct):>0.2f}%, Train_loss: {train_loss:>8f}, Test_accuracy: {(100*test_correct):>0.2f}%, Test_loss: {test_loss:>8f}\")\n",
    "                    print(f\"Time taken on last epoch: {train_time_taken:>0.2f}s\")\n",
    "                    break\n",
    "        \n",
    "        print(f\"Average cross_validation_times: {train_time_taken_total/no_folds:>.2f}s\")      \n",
    "        print(f\"Average cross_validation_accuracies: {val_correct_total/no_folds*100:>.2f}%\")  \n",
    "                  \n",
    "        cross_validation_times.append(train_time_taken_total / no_folds) \n",
    "        cross_validation_accuracies.append(val_correct_total / no_folds) \n",
    "        \n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "\n",
    "\n",
    "\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, 'batch_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69421943e22521de848bb03a50f57767",
     "grade": false,
     "grade_id": "a2_1_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "5. Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03b7f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter([str(bs) for bs in batch_sizes], cross_validation_accuracies, marker = 'x')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Mean cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e8d298b5774c4044f1c3f950c46214",
     "grade": false,
     "grade_id": "a2_1_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "6. Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "058358df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Last Epoch Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.110208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.080674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.054710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.040435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Last Epoch Time\n",
       "0         128         0.110208\n",
       "1         256         0.080674\n",
       "2         512         0.054710\n",
       "3        1024         0.040435"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Batch Size': batch_sizes,\n",
    "                   'Last Epoch Time': cross_validation_times\n",
    "                  })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
   "metadata": {
    "deletable": false,
    "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38690f32ec506325fc73c8353b77d041",
     "grade": false,
     "grade_id": "batch_size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal batch size: 256\n",
      "Reason: From the scatter plot, we can see that as batch size increases, cross validation accuracy decreases. \n",
      "    Upon increasing the batch size from 256 to 512, the cross validation accuracy dropped significantly. \n",
      "    This indicates the best batch size is between 128 and 256, as the cross validation accuracy of batch size 512 and 1024 is considerably lower compared to batch size 128 and 256. \n",
      "    Between 128 and 256, cross validation accuracy is comparable with each other, with batch size 128 only performing slightly better. \n",
      "    From the time taken to train as shown in the dataframe, using batch size 256 was faster than when batch size 128 was use. \n",
      "    The additional advantage of performing faster indicates batch size 256 is the optimal batch size. \n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = \"256\"\n",
    "reason = \"From the scatter plot, we can see that as batch size increases, cross validation accuracy decreases. \\n\\\n",
    "    Upon increasing the batch size from 256 to 512, the cross validation accuracy dropped significantly. \\n\\\n",
    "    This indicates the best batch size is between 128 and 256, as the cross validation accuracy of batch size 512 and 1024 is considerably lower compared to batch size 128 and 256. \\n\\\n",
    "    Between 128 and 256, cross validation accuracy is comparable with each other, with batch size 128 only performing slightly better. \\n\\\n",
    "    From the time taken to train as shown in the dataframe, using batch size 256 was faster than when batch size 128 was use. \\n\\\n",
    "    The additional advantage of performing faster indicates batch size 256 is the optimal batch size. \"\n",
    "\n",
    "print(\"Optimal batch size:\", optimal_batch_size)\n",
    "print(\"Reason:\", reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f695b961ed43ec6a31b7647e078fd8d6",
     "grade": true,
     "grade_id": "correct_batch_size",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
