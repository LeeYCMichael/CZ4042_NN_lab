{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "987c7c95a0c7dc71b3d85e154cc3a9be",
     "grade": false,
     "grade_id": "cell-6ebb8bd2f22353d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Question A4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f824c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5c8f824c",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17d770ae590711dc06f03d150970a3f1",
     "grade": false,
     "grade_id": "cell-e34b0415c38ebac4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this section, we will understand the utility of such a neural network in real world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "287259c58079728b66dae175c6082400",
     "grade": false,
     "grade_id": "cell-4f74b97314b65ea1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Please use the real record data named ‘record.wav’  as a test sample. Preprocess the data using the provided preprocessing script (data_preprocess.ipynb) and prepare the dataset.\n",
    "Do a model prediction on the sample test dataset and obtain the predicted label using a threshold of 0.5. The model used is the optimized pretrained model using the selected optimal batch size and optimal number of neurons.\n",
    "Find the most important features on the model prediction for the test sample using SHAP. Plot the local feature importance with a force plot and explain your observations.  (Refer to the documentation and these three useful references:\n",
    "https://christophm.github.io/interpretable-ml-book/shap.html#examples-5,\n",
    "https://towardsdatascience.com/deep-learning-model-interpretation-using-shap-a21786e91d16,  \n",
    "https://medium.com/mlearning-ai/shap-force-plots-for-classification-d30be430e195)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c85ca-9a14-4d0a-b44d-814f02c0f8e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "981c85ca-9a14-4d0a-b44d-814f02c0f8e1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30c3b93836aad148380e15933e7dd786",
     "grade": false,
     "grade_id": "cell-b8a265bf37e3b271",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "1. Firstly, we import relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c50f4f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "58c50f4f",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f6af6091e2832c850b00e735d1cff11",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3444c83",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d3444c83",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d796a3a33dd56bd5afb55de45b642449",
     "grade": false,
     "grade_id": "cell-293c9e85ad81d29a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To reduce repeated code, place your\n",
    "network (MLP defined in QA1)\n",
    "torch datasets (CustomDataset defined in QA1)\n",
    "loss function (loss_fn defined in QA1)\n",
    "in a separate file called common_utils.py\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e8e840",
   "metadata": {
    "deletable": false,
    "id": "72e8e840",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c623c0417cb6065d1bbb049f211cf1c",
     "grade": false,
     "grade_id": "cell-29dace0045a28b89",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "from common_utils import *\n",
    "\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd5d5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "18fd5d5e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7da5539e4fe97549a11c7d61be647167",
     "grade": false,
     "grade_id": "cell-1c5bf554b8f89a3d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "2. Install and import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49be1fc",
   "metadata": {
    "deletable": false,
    "id": "e49be1fc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f58a0104d88201d0af7de9fc3a6ca035",
     "grade": false,
     "grade_id": "import_shap",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fde60a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5fde60a",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b8877105a451813ab23b45e9a180bc36",
     "grade": false,
     "grade_id": "cell-82dd5a271bf5af4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "3. Read the csv data preprocessed from 'record.wav', using variable name 'df', and fill the size of 'df' in 'size_row' and 'size_column'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a54d47",
   "metadata": {
    "deletable": false,
    "id": "81a54d47",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c35348846173e5c042d78be10546ae86",
     "grade": false,
     "grade_id": "cell-01d5f7ef70e69e09",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df = pd.read_csv('new_record.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "df['label'].value_counts()\n",
    "\n",
    "size_row = len(df)\n",
    "size_column = len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3d13eea6f0ed0d345e10f33dd3a26da",
     "grade": false,
     "grade_id": "cell-7096e580d10284df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " 4.  Preprocess to obtain the test data, save the test data as numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c77bd18-c546-473e-8c2f-643b4281d9ba",
   "metadata": {
    "deletable": false,
    "id": "8c77bd18-c546-473e-8c2f-643b4281d9ba",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b19be33055efd5fc5d562a9c671b6eb2",
     "grade": false,
     "grade_id": "cell-b1e392e8ecab207a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(X_train, df):\n",
    "    \"\"\"preprocess your dataset to obtain your test dataset, remember to remove the 'filename' as Q1\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    columns_to_drop = ['filename', 'label']\n",
    "    df2 = df.drop(columns_to_drop,axis=1)\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    X_test_scaled = standard_scaler.fit_transform(df2)\n",
    "\n",
    "    return X_test_scaled\n",
    "\n",
    "X_train= []\n",
    "X_test_scaled_eg = preprocess(X_train, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7359ce09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>tempo</th>\n",
       "      <th>total_beats</th>\n",
       "      <th>average_beats</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>chroma_cq_mean</th>\n",
       "      <th>chroma_cq_var</th>\n",
       "      <th>chroma_cens_mean</th>\n",
       "      <th>chroma_cens_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc15_var</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record.wav</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>51</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.478361</td>\n",
       "      <td>0.111058</td>\n",
       "      <td>0.579547</td>\n",
       "      <td>0.091646</td>\n",
       "      <td>0.268037</td>\n",
       "      <td>0.01149</td>\n",
       "      <td>...</td>\n",
       "      <td>46.232433</td>\n",
       "      <td>-4.134901</td>\n",
       "      <td>53.040028</td>\n",
       "      <td>-0.942353</td>\n",
       "      <td>35.105545</td>\n",
       "      <td>-3.529712</td>\n",
       "      <td>54.78144</td>\n",
       "      <td>-3.722852</td>\n",
       "      <td>53.242016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename       tempo  total_beats  average_beats  chroma_stft_mean  \\\n",
       "0  record.wav  112.347147           51           25.5          0.478361   \n",
       "\n",
       "   chroma_stft_var  chroma_cq_mean  chroma_cq_var  chroma_cens_mean  \\\n",
       "0         0.111058        0.579547       0.091646          0.268037   \n",
       "\n",
       "   chroma_cens_var  ...  mfcc15_var  mfcc16_mean  mfcc16_var  mfcc17_mean  \\\n",
       "0          0.01149  ...   46.232433    -4.134901   53.040028    -0.942353   \n",
       "\n",
       "   mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  label  \n",
       "0   35.105545    -3.529712    54.78144    -3.722852   53.242016    NaN  \n",
       "\n",
       "[1 rows x 79 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96d2e019d65c49ba15b3089c2184f021",
     "grade": false,
     "grade_id": "cell-48b4edbfec330f39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "5. Do a model prediction on the sample test dataset and obtain the predicted label using a threshold of 0.5. The model used is the optimized pretrained model using the selected optimal batch size and optimal number of neurons. Note: Please define the variable of your final predicted label as 'pred_label'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
   "metadata": {
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "276ec9575db4ca701823a459809ea810",
     "grade": true,
     "grade_id": "cell-e83cb49660edc2b7",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2fc2cc-b89f-4fc3-af16-e30b4e5315a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "da2fc2cc-b89f-4fc3-af16-e30b4e5315a3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "704df2be8fbd85ba163a89cd2e0431f0",
     "grade": true,
     "grade_id": "predict_value",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eac3438866b5ebd40f5fb20a676059bd",
     "grade": false,
     "grade_id": "cell-896f18b6b0b948ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "6. Find the most important features on the model prediction for your test sample using SHAP. Create an instance of the DeepSHAP which is called DeepExplainer using traianing dataset: https://shap-lrjball.readthedocs.io/en/latest/generated/shap.DeepExplainer.html.\n",
    "\n",
    "Plot the local feature importance with a force plot and explain your observations.  (Refer to the documentation and these three useful references:\n",
    "https://christophm.github.io/interpretable-ml-book/shap.html#examples-5,\n",
    "https://towardsdatascience.com/deep-learning-model-interpretation-using-shap-a21786e91d16,  \n",
    "https://medium.com/mlearning-ai/shap-force-plots-for-classification-d30be430e195)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
   "metadata": {
    "deletable": false,
    "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db46b1b26fd45359768421987104ac3e",
     "grade": true,
     "grade_id": "importance_weight",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Fit the explainer on a subset of the data (you can try all but then gets slower)\n",
    "Return approximate SHAP values for the model applied to the data given by X.\n",
    "Plot the local feature importance with a force plot and explain your observations.\n",
    "'''\n",
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
