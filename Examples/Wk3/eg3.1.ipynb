{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:[[ 0.5  -1.66]\n",
      " [-1.   -0.51]\n",
      " [ 0.78 -0.65]\n",
      " [ 0.04 -0.2 ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0.5, -1.66],[-1.0, -0.51],[0.78, -0.65],[0.04, -0.20]])\n",
    "print('x:{}'.format(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class for a perceptron layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronLayer():\n",
    "  def __init__(self, no_features, no_labels):\n",
    "    self.w = torch.tensor(np.random.normal(0., 0.1, (no_features, no_labels)), dtype=torch.double)\n",
    "    self.b = torch.tensor(0.1*np.random.rand(no_labels), dtype=torch.double)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    u = torch.matmul(torch.tensor(x), self.w) + self.b\n",
    "    y = torch.sigmoid(u)\n",
    "    return u, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the given layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [[ 0.13315865  0.0715279  -0.15454003]\n",
      " [-0.00083838  0.0621336  -0.07200856]], b: [0.01691108 0.00883398 0.06853598]\n"
     ]
    }
   ],
   "source": [
    "model = PerceptronLayer(2, 3)\n",
    "\n",
    "print('w: {}, b: {}'.format(model.w.numpy(), model.b.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find activations and outputs of the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u:[[ 0.08488213 -0.05854384  0.11080017]\n",
      " [-0.11581999 -0.09438205  0.25980037]\n",
      " [ 0.12131978  0.0242389  -0.00519968]\n",
      " [ 0.02240511 -0.00073162  0.07675609]]\n",
      "y:[[0.5212078  0.48536822 0.52767174]\n",
      " [0.47107733 0.47642199 0.56458722]\n",
      " [0.5302928  0.50605943 0.49870008]\n",
      " [0.50560104 0.49981709 0.51917961]]\n"
     ]
    }
   ],
   "source": [
    "u, y = model(X)\n",
    "\n",
    "print('u:{}'.format(u.numpy()))\n",
    "print('y:{}'.format(y.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
